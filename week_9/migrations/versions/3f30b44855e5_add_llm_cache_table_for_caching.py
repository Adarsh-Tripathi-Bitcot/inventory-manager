"""Add llm_cache table for caching

Revision ID: 3f30b44855e5
Revises: 4a9448b7eb38
Create Date: 2025-09-09 12:44:14.673217

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
import pgvector.sqlalchemy

# revision identifiers, used by Alembic.
revision = '3f30b44855e5'
down_revision = '4a9448b7eb38'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('langchain_pg_embedding')
    op.drop_table('langchain_pg_collection')
    with op.batch_alter_table('llm_cache', schema=None) as batch_op:
        batch_op.add_column(sa.Column('expiration_time', sa.DateTime(timezone=True), nullable=True))
        batch_op.alter_column('model_name',
               existing_type=sa.VARCHAR(length=128),
               type_=sa.String(length=50),
               existing_nullable=False)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
        batch_op.drop_constraint(batch_op.f('uix_model_prompt'), type_='unique')
        batch_op.create_unique_constraint(None, ['prompt'])
        batch_op.drop_column('updated_at')

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('llm_cache', schema=None) as batch_op:
        batch_op.add_column(sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
        batch_op.drop_constraint(None, type_='unique')
        batch_op.create_unique_constraint(batch_op.f('uix_model_prompt'), ['model_name', 'prompt'], postgresql_nulls_not_distinct=False)
        batch_op.alter_column('created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
        batch_op.alter_column('model_name',
               existing_type=sa.String(length=50),
               type_=sa.VARCHAR(length=128),
               existing_nullable=False)
        batch_op.drop_column('expiration_time')

    op.create_table('langchain_pg_collection',
    sa.Column('name', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('cmetadata', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('uuid', sa.UUID(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('uuid', name='langchain_pg_collection_pkey'),
    postgresql_ignore_search_path=False
    )
    op.create_table('langchain_pg_embedding',
    sa.Column('collection_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('embedding', pgvector.sqlalchemy.vector.VECTOR(), autoincrement=False, nullable=True),
    sa.Column('document', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('cmetadata', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('custom_id', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('uuid', sa.UUID(), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['collection_id'], ['langchain_pg_collection.uuid'], name=op.f('langchain_pg_embedding_collection_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('uuid', name=op.f('langchain_pg_embedding_pkey'))
    )
    # ### end Alembic commands ###
